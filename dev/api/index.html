<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · SymbolicRegression.jl</title><link rel="canonical" href="https://astroautomata.com/SymbolicRegression.jl/stable/api/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SymbolicRegression.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">SymbolicRegression.jl</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#EquationSearch"><span>EquationSearch</span></a></li><li><a class="tocitem" href="#Options"><span>Options</span></a></li><li><a class="tocitem" href="#Printing-and-Evaluation"><span>Printing and Evaluation</span></a></li><li><a class="tocitem" href="#SymbolicUtils.jl-interface"><span>SymbolicUtils.jl interface</span></a></li><li><a class="tocitem" href="#Pareto-frontier"><span>Pareto frontier</span></a></li></ul></li><li><a class="tocitem" href="../losses/">Losses</a></li><li><a class="tocitem" href="../types/">Types</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h1><h2 id="EquationSearch"><a class="docs-heading-anchor" href="#EquationSearch">EquationSearch</a><a id="EquationSearch-1"></a><a class="docs-heading-anchor-permalink" href="#EquationSearch" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.EquationSearch-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray{T,1}}} where T&lt;:Real" href="#SymbolicRegression.EquationSearch-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray{T,1}}} where T&lt;:Real"><code>SymbolicRegression.EquationSearch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">EquationSearch(X, y[; kws...])</code></pre><p>Perform a distributed equation search for functions which describe the mapping f(X[:, j]) ≈ y[j]. Options are configured using SymbolicRegression.Options(...), which should be passed as a keyword argument to options. One can turn off parallelism with <code>numprocs=0</code>, which is useful for debugging and profiling.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix{T}</code>:  The input dataset to predict <code>y</code> from.   The first dimension is features, the second dimension is rows.</li><li><code>y::AbstractVector{T}</code>: The values to predict. Only a single feature   is allowed, so <code>y</code> is a 1D array.</li><li><code>niterations::Int=10</code>: The number of iterations to perform the search.   More iterations will improve the results.</li><li><code>weights::Union{AbstractVector{T}, Nothing}=nothing</code>: Optionally   weight the loss for each <code>y</code> by this value (same shape as <code>y</code>).</li><li><code>varMap::Union{Array{String, 1}, Nothing}=nothing</code>: The names   of each feature in <code>X</code>, which will be used during printing of equations.</li><li><code>options::Options=Options()</code>: The options for the search, such as   which operators to use, evolution hyperparameters, etc.</li><li><code>numprocs::Union{Int, Nothing}=nothing</code>:  The number of processes to use,   if you want <code>EquationSearch</code> to set this up automatically. By default   this will be <code>4</code>, but can be any number (you should pick a number &lt;=   the number of cores available).</li><li><code>procs::Union{Array{Int, 1}, Nothing}=nothing</code>: If you have set up   a distributed run manually with <code>procs = addprocs()</code> and <code>@everywhere</code>,   pass the <code>procs</code> to this keyword argument.</li><li><code>runtests::Bool=true</code>: Whether to run (quick) tests before starting the   search, to see if there will be any problems during the equation search   related to the host environment.</li></ul><p><strong>Returns</strong></p><ul><li><code>hallOfFame::HallOfFame</code>: The best equations seen during the search.   hallOfFame.members gives an array of <code>PopMember</code> objects, which   have their tree (equation) stored in <code>.tree</code>. Their score (loss)   is given in <code>.score</code>. The array of <code>PopMember</code> objects   is enumerated by size from <code>1</code> to <code>options.maxsize</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/SymbolicRegression.jl#L73-L113">source</a></section></article><h2 id="Options"><a class="docs-heading-anchor" href="#Options">Options</a><a id="Options-1"></a><a class="docs-heading-anchor-permalink" href="#Options" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../Options.jl.Options-Union{Tuple{}, Tuple{nbin}, Tuple{nuna}} where nbin where nuna" href="#SymbolicRegression.../Options.jl.Options-Union{Tuple{}, Tuple{nbin}, Tuple{nuna}} where nbin where nuna"><code>SymbolicRegression.../Options.jl.Options</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">Options(;kws...)</code></pre><p>Construct options for <code>EquationSearch</code> and other functions.</p><p><strong>Arguments</strong></p><ul><li><code>binary_operators=(div, plus, mult)</code>: Tuple of binary   operators to use. Each operator should be defined for two input scalars,   and one output scalar. All operators need to be defined over the entire   real line (excluding infinity - these are stopped before they are input).   Thus, <code>log</code> should be replaced with <code>log_abs</code>, etc.   For speed, define it so it takes two reals   of the same type as input, and outputs the same type. For the SymbolicUtils   simplification backend, you will need to define a generic method of the   operator so it takes arbitrary types.</li><li><code>unary_operators=(exp, cos)</code>: Same, but for   unary operators (one input scalar, gives an output scalar).</li><li><code>constraints=nothing</code>: Array of pairs specifying size constraints   for each operator. The constraints for a binary operator should be a 2-tuple   (e.g., <code>(-1, -1)</code>) and the constraints for a unary operator should be an <code>Int</code>.   A size constraint is a limit to the size of the subtree   in each argument of an operator. e.g., <code>[(^)=&gt;(-1, 3)]</code> means that the   <code>^</code> operator can have arbitrary size (<code>-1</code>) in its left argument,   but a maximum size of <code>3</code> in its right argument. Default is   no constraints.</li><li><code>batching=false</code>: Whether to evolve based on small mini-batches of data,   rather than the entire dataset.</li><li><code>batchSize=50</code>: What batch size to use if using batching.</li><li><code>loss=L2DistLoss()</code>: What loss function to use. Can be one of   the following losses, or any other loss of type   <code>SupervisedLoss</code>. You can also pass a function that takes   a scalar target (left argument), and scalar predicted (right   argument), and returns a scalar. This will be averaged   over the predicted data. If weights are supplied, your   function should take a third argument for the weight scalar.   Included losses:       Regression:           - <code>LPDistLoss{P}()</code>,           - <code>L1DistLoss()</code>,           - <code>L2DistLoss()</code> (mean square),           - <code>LogitDistLoss()</code>,           - <code>HuberLoss(d)</code>,           - <code>L1EpsilonInsLoss(ϵ)</code>,           - <code>L2EpsilonInsLoss(ϵ)</code>,           - <code>PeriodicLoss(c)</code>,           - <code>QuantileLoss(τ)</code>,       Classification:           - <code>ZeroOneLoss()</code>,           - <code>PerceptronLoss()</code>,           - <code>L1HingeLoss()</code>,           - <code>SmoothedL1HingeLoss(γ)</code>,           - <code>ModifiedHuberLoss()</code>,           - <code>L2MarginLoss()</code>,           - <code>ExpLoss()</code>,           - <code>SigmoidLoss()</code>,           - <code>DWDMarginLoss(q)</code>.</li><li><code>npopulations=nothing</code>: How many populations of equations to use. By default   this is set equal to the number of cores</li><li><code>npop=1000</code>: How many equations in each population.</li><li><code>ncyclesperiteration=300</code>: How many generations to consider per iteration.</li><li><code>ns=10</code>: Number of equations in each subsample during regularized evolution.</li><li><code>topn=10</code>: Number of equations to return to the host process, and to   consider for the hall of fame.</li><li><code>alpha=0.100000f0</code>: The probability of accepting an equation mutation   during regularized evolution is given by exp(-delta_loss/(alpha * T)),   where T goes from 1 to 0. Thus, alpha=infinite is the same as no annealing.</li><li><code>maxsize=20</code>: Maximum size of equations during the search.</li><li><code>maxdepth=nothing</code>: Maximum depth of equations during the search, by default   this is set equal to the maxsize.</li><li><code>parsimony=0.000100f0</code>: A multiplicative factor for how much complexity is   punished.</li><li><code>useFrequency=false</code>: Whether to use a parsimony that adapts to the   relative proportion of equations at each complexity; this will   ensure that there are a balanced number of equations considered   for every complexity.</li><li><code>fast_cycle=false</code>: Whether to thread over subsamples of equations during   regularized evolution. Slightly improves performance, but is a different   algorithm.</li><li><code>migration=true</code>: Whether to migrate equations between processes.</li><li><code>hofMigration=true</code>: Whether to migrate equations from the hall of fame   to processes.</li><li><code>fractionReplaced=0.1f0</code>: What fraction of each population to replace with   migrated equations at the end of each cycle.</li><li><code>fractionReplacedHof=0.1f0</code>: What fraction to replace with hall of fame   equations at the end of each cycle.</li><li><code>shouldOptimizeConstants=true</code>: Whether to use NelderMead optimization   to periodically optimize constants in equations.</li><li><code>nrestarts=3</code>: How many different random starting positions to consider   when using NelderMead optimization.</li><li><code>hofFile=nothing</code>: What file to store equations to, as a backup.</li><li><code>perturbationFactor=1.000000f0</code>: When mutating a constant, either   multiply or divide by (1+perturbationFactor)^(rand()+1).</li><li><code>probNegate=0.01f0</code>: Probability of negating a constant in the equation   when mutating it.</li><li><code>mutationWeights=[10.000000, 1.000000, 1.000000, 3.000000, 3.000000, 0.010000, 1.000000, 1.000000]</code>:</li><li><code>annealing=true</code>: Whether to use simulated annealing.</li><li><code>warmupMaxsize=0</code>: Whether to slowly increase the max size from 5 up to   <code>maxsize</code>. If nonzero, specifies how many cycles (populations*iterations)   before increasing by 1.</li><li><code>verbosity=convert(Int, 1e9)</code>: Whether to print debugging statements or   not.</li><li><code>bin_constraints=nothing</code>:</li><li><code>una_constraints=nothing</code>:</li><li><code>seed=nothing</code>: What random seed to use. <code>nothing</code> uses no seed.</li><li><code>progress=false</code>: Whether to use a progress bar output (<code>verbosity</code> will   have no effect).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/Options.jl#L139-L245">source</a></section></article><h2 id="Printing-and-Evaluation"><a class="docs-heading-anchor" href="#Printing-and-Evaluation">Printing and Evaluation</a><a id="Printing-and-Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Printing-and-Evaluation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../EquationUtils.jl.stringTree-Tuple{Node,Options}" href="#SymbolicRegression.../EquationUtils.jl.stringTree-Tuple{Node,Options}"><code>SymbolicRegression.../EquationUtils.jl.stringTree</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stringTree(tree::Node, options::Options; kws...)</code></pre><p>Convert an equation to a string.</p><p><strong>Arguments</strong></p><ul><li><code>varMap::Union{Array{String, 1}, Nothing}=nothing</code>: what variables   to print for each feature.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/EquationUtils.jl#L44-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../EvaluateEquation.jl.evalTreeArray-Union{Tuple{T}, Tuple{Node,AbstractArray{T,2},Options}} where T&lt;:Real" href="#SymbolicRegression.../EvaluateEquation.jl.evalTreeArray-Union{Tuple{T}, Tuple{Node,AbstractArray{T,2},Options}} where T&lt;:Real"><code>SymbolicRegression.../EvaluateEquation.jl.evalTreeArray</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">evalTreeArray(tree::Node, cX::AbstractMatrix{T}, options::Options)</code></pre><p>Evaluate a binary tree (equation) over a given input data matrix. The options contain all of the operators used. This function fuses doublets and triplets of operations for lower memory usage.</p><p><strong>Returns</strong></p><ul><li><code>(output, complete)::Tuple{AbstractVector{T}, Bool}</code>: the result,   which is a 1D array, as well as if the evaluation completed   successfully (true/false). A <code>false</code> complete means an infinity   or nan was encountered, and a large loss should be assigned   to the equation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/EvaluateEquation.jl#L5-L19">source</a></section></article><h2 id="SymbolicUtils.jl-interface"><a class="docs-heading-anchor" href="#SymbolicUtils.jl-interface">SymbolicUtils.jl interface</a><a id="SymbolicUtils.jl-interface-1"></a><a class="docs-heading-anchor-permalink" href="#SymbolicUtils.jl-interface" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../InterfaceSymbolicUtils.jl.node_to_symbolic-Tuple{Node,Options}" href="#SymbolicRegression.../InterfaceSymbolicUtils.jl.node_to_symbolic-Tuple{Node,Options}"><code>SymbolicRegression.../InterfaceSymbolicUtils.jl.node_to_symbolic</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">node_to_symbolic(tree::Node, options::Options;
            varMap::Union{Array{String, 1}, Nothing}=nothing,
            evaluate_functions::Bool=false,
            index_functions::Bool=false)</code></pre><p>The interface to SymbolicUtils.jl. Passing a tree to this function will generate a symbolic equation in SymbolicUtils.jl format.</p><p><strong>Arguments</strong></p><ul><li><code>tree::Node</code>: The equation to convert.</li><li><code>options::Options</code>: Options, which contains the operators used in the equation.</li><li><code>varMap::Union{Array{String, 1}, Nothing}=nothing</code>: What variable names to use for   each feature. Default is [x1, x2, x3, ...].</li><li><code>evaluate_functions::Bool=false</code>: Whether to evaluate the operators, or   leave them as symbolic.</li><li><code>index_functions::Bool=false</code>: Whether to generate special names for the   operators, which then allows one to convert back to a <code>Node</code> format   using <code>symbolic_to_node</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/InterfaceSymbolicUtils.jl#L7-L27">source</a></section></article><h2 id="Pareto-frontier"><a class="docs-heading-anchor" href="#Pareto-frontier">Pareto frontier</a><a id="Pareto-frontier-1"></a><a class="docs-heading-anchor-permalink" href="#Pareto-frontier" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray{T,1},HallOfFame,Options}} where T&lt;:Real" href="#SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier-Union{Tuple{T}, Tuple{AbstractArray{T,2},AbstractArray{T,1},HallOfFame,Options}} where T&lt;:Real"><code>SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">calculateParetoFrontier(X::AbstractMatrix{T}, y::AbstractVector{T},
                        hallOfFame::HallOfFame, options::Options;
                        weights=nothing, varMap=nothing) where {T&lt;:Real}</code></pre><p>Compute the dominating Pareto frontier for a given hallOfFame. This is the list of equations where each equation has a better loss than all simpler equations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/HallOfFame.jl#L59-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier-Union{Tuple{T}, Tuple{Dataset{T},HallOfFame,Options}} where T&lt;:Real" href="#SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier-Union{Tuple{T}, Tuple{Dataset{T},HallOfFame,Options}} where T&lt;:Real"><code>SymbolicRegression.../HallOfFame.jl.calculateParetoFrontier</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">calculateParetoFrontier(dataset::Dataset{T}, hallOfFame::HallOfFame,
                        options::Options) where {T&lt;:Real}</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilesCranmer/SymbolicRegression.jl/blob/6d12b4a273f3b0037e1cf145472ff3844e3d5366/src/HallOfFame.jl#L31-L34">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« SymbolicRegression.jl</a><a class="docs-footer-nextpage" href="../losses/">Losses »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 28 February 2021 12:26">Sunday 28 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
