var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#EquationSearch","page":"API","title":"EquationSearch","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"EquationSearch(X::AbstractMatrix{T}, y::AbstractMatrix{T};\n        niterations::Int=10,\n        weights::Union{AbstractVector{T}, Nothing}=nothing,\n        varMap::Union{Array{String, 1}, Nothing}=nothing,\n        options::Options=Options(),\n        numprocs::Union{Int, Nothing}=nothing,\n        procs::Union{Array{Int, 1}, Nothing}=nothing,\n        runtests::Bool=true\n       ) where {T<:Real}","category":"page"},{"location":"api/#SymbolicRegression.EquationSearch-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}}} where T<:Real","page":"API","title":"SymbolicRegression.EquationSearch","text":"EquationSearch(X, y[; kws...])\n\nPerform a distributed equation search for functions f_i which describe the mapping f_i(X[:, j]) ≈ y[i, j]. Options are configured using SymbolicRegression.Options(...), which should be passed as a keyword argument to options. One can turn off parallelism with numprocs=0, which is useful for debugging and profiling.\n\nArguments\n\nX::AbstractMatrix{T}:  The input dataset to predict y from.   The first dimension is features, the second dimension is rows.\ny::Union{AbstractMatrix{T}, AbstractVector{T}}: The values to predict. The first dimension   is the output feature to predict with each equation, and the   second dimension is rows.\nniterations::Int=10: The number of iterations to perform the search.   More iterations will improve the results.\nweights::Union{AbstractMatrix{T}, AbstractVector{T}, Nothing}=nothing: Optionally   weight the loss for each y by this value (same shape as y).\nvarMap::Union{Array{String, 1}, Nothing}=nothing: The names   of each feature in X, which will be used during printing of equations.\noptions::Options=Options(): The options for the search, such as   which operators to use, evolution hyperparameters, etc.\nnumprocs::Union{Int, Nothing}=nothing:  The number of processes to use,   if you want EquationSearch to set this up automatically. By default   this will be 4, but can be any number (you should pick a number <=   the number of cores available).\nprocs::Union{Array{Int, 1}, Nothing}=nothing: If you have set up   a distributed run manually with procs = addprocs() and @everywhere,   pass the procs to this keyword argument.\nmultithreading::Bool=false: Whether to use multithreading. Otherwise,   will use multiprocessing. Multithreading uses less memory, but multiprocessing   can handle multi-node compute.\nruntests::Bool=true: Whether to run (quick) tests before starting the   search, to see if there will be any problems during the equation search   related to the host environment.\nsaved_state::Union{StateType, Nothing}=nothing: If you have already   run EquationSearch and want to resume it, pass the state here.   To get this to work, you need to have stateReturn=true in the options,   which will cause EquationSearch to return the state. Note that   you cannot change the operators or dataset, but most other options   should be changeable.\naddprocs_function::Union{Function, Nothing}=nothing: If using distributed   mode (multithreading=false), you may pass a custom function to use   instead of addprocs. This function should take a single positional argument,   which is the number of processes to use, as well as the lazy keyword argument.   For example, if set up on a slurm cluster, you could pass   addprocs_function = addprocs_slurm, which will set up slurm processes.\n\nReturns\n\nhallOfFame::HallOfFame: The best equations seen during the search.   hallOfFame.members gives an array of PopMember objects, which   have their tree (equation) stored in .tree. Their score (loss)   is given in .score. The array of PopMember objects   is enumerated by size from 1 to options.maxsize.\n\n\n\n\n\n","category":"method"},{"location":"api/#Options","page":"API","title":"Options","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Options(;\n    binary_operators::NTuple{nbin, Any}=(div, plus, mult),\n    unary_operators::NTuple{nuna, Any}=(exp, cos),\n    bin_constraints=nothing,\n    una_constraints=nothing,\n    ns=10, #1 sampled from every ns per mutation\n    topn=10, #samples to return per population\n    parsimony=0.000100f0,\n    alpha=0.100000f0,\n    maxsize=20,\n    maxdepth=nothing,\n    fast_cycle=false,\n    migration=true,\n    hofMigration=true,\n    fractionReplacedHof=0.1f0,\n    shouldOptimizeConstants=true,\n    hofFile=nothing,\n    npopulations=nothing,\n    nrestarts=3,\n    perturbationFactor=1.000000f0,\n    annealing=true,\n    batching=false,\n    batchSize=50,\n    mutationWeights=[10.000000, 1.000000, 1.000000, 3.000000, 3.000000, 0.010000, 1.000000, 1.000000],\n    warmupMaxsize=0,\n    useFrequency=false,\n    npop=1000,\n    ncyclesperiteration=300,\n    fractionReplaced=0.1f0,\n    verbosity=convert(Int, 1e9),\n    probNegate=0.01f0,\n    seed=nothing\n   ) where {nuna,nbin}","category":"page"},{"location":"api/#SymbolicRegression.CoreModule.OptionsStructModule.Options-Union{Tuple{}, Tuple{nbin}, Tuple{nuna}} where {nuna, nbin}","page":"API","title":"SymbolicRegression.CoreModule.OptionsStructModule.Options","text":"Options(;kws...)\n\nConstruct options for EquationSearch and other functions. The current arguments have been tuned using the median values from https://github.com/MilesCranmer/PySR/discussions/115.\n\nArguments\n\nbinary_operators: Tuple of binary operators to use. Each operator should   be defined for two input scalars, and one output scalar. All operators   need to be defined over the entire real line (excluding infinity - these   are stopped before they are input), or return NaN where not defined.   Thus, log should be replaced with safe_log, etc.   For speed, define it so it takes two reals   of the same type as input, and outputs the same type. For the SymbolicUtils   simplification backend, you will need to define a generic method of the   operator so it takes arbitrary types.\nunary_operators: Same, but for   unary operators (one input scalar, gives an output scalar).\nconstraints: Array of pairs specifying size constraints   for each operator. The constraints for a binary operator should be a 2-tuple   (e.g., (-1, -1)) and the constraints for a unary operator should be an Int.   A size constraint is a limit to the size of the subtree   in each argument of an operator. e.g., [(^)=>(-1, 3)] means that the   ^ operator can have arbitrary size (-1) in its left argument,   but a maximum size of 3 in its right argument. Default is   no constraints.\nbatching: Whether to evolve based on small mini-batches of data,   rather than the entire dataset.\nbatchSize: What batch size to use if using batching.\nloss: What loss function to use. Can be one of   the following losses, or any other loss of type   SupervisedLoss. You can also pass a function that takes   a scalar target (left argument), and scalar predicted (right   argument), and returns a scalar. This will be averaged   over the predicted data. If weights are supplied, your   function should take a third argument for the weight scalar.   Included losses:       Regression:           - LPDistLoss{P}(),           - L1DistLoss(),           - L2DistLoss() (mean square),           - LogitDistLoss(),           - HuberLoss(d),           - L1EpsilonInsLoss(ϵ),           - L2EpsilonInsLoss(ϵ),           - PeriodicLoss(c),           - QuantileLoss(τ),       Classification:           - ZeroOneLoss(),           - PerceptronLoss(),           - L1HingeLoss(),           - SmoothedL1HingeLoss(γ),           - ModifiedHuberLoss(),           - L2MarginLoss(),           - ExpLoss(),           - SigmoidLoss(),           - DWDMarginLoss(q).\nnpopulations: How many populations of equations to use. By default   this is set equal to the number of cores\nnpop: How many equations in each population.\nncyclesperiteration: How many generations to consider per iteration.\nns: Number of equations in each subsample during regularized evolution.\ntopn: Number of equations to return to the host process, and to   consider for the hall of fame.\ncomplexity_of_operators: What complexity should be assigned to each operator,   and the occurrence of a constant or variable. By default, this is 1   for all operators. Can be a real number as well, in which case   the complexity of an expression will be rounded to the nearest integer.   Input this in the form of, e.g., [(^) => 3, sin => 2].\ncomplexity_of_constants: What complexity should be assigned to use of a constant.   By default, this is 1.\ncomplexity_of_variables: What complexity should be assigned to each variable.   By default, this is 1.\nalpha: The probability of accepting an equation mutation   during regularized evolution is given by exp(-delta_loss/(alpha * T)),   where T goes from 1 to 0. Thus, alpha=infinite is the same as no annealing.\nmaxsize: Maximum size of equations during the search.\nmaxdepth: Maximum depth of equations during the search, by default   this is set equal to the maxsize.\nparsimony: A multiplicative factor for how much complexity is   punished.\nuseFrequency: Whether to use a parsimony that adapts to the   relative proportion of equations at each complexity; this will   ensure that there are a balanced number of equations considered   for every complexity.\nuseFrequencyInTournament: Whether to use the adaptive parsimony described   above inside the score, rather than just at the mutation accept/reject stage.\nfast_cycle: Whether to thread over subsamples of equations during   regularized evolution. Slightly improves performance, but is a different   algorithm.\nmigration: Whether to migrate equations between processes.\nhofMigration: Whether to migrate equations from the hall of fame   to processes.\nfractionReplaced: What fraction of each population to replace with   migrated equations at the end of each cycle.\nfractionReplacedHof: What fraction to replace with hall of fame   equations at the end of each cycle.\nshouldOptimizeConstants: Whether to use an optimization algorithm   to periodically optimize constants in equations.\noptimizer_nrestarts: How many different random starting positions to consider   for optimization of constants.\noptimizer_algorithm: Select algorithm to use for optimizing constants. Default   is \"BFGS\", but \"NelderMead\" is also supported.\noptimizer_options: General options for the constant optimization. For details   we refer to the documentation on Optim.Options from the Optim.jl package.   Options can be provided here as NamedTuple, e.g. (iterations=16,), as a   Dict, e.g. Dict(:x_tol => 1.0e-32,), or as an Optim.Options instance.\nhofFile: What file to store equations to, as a backup.\nperturbationFactor: When mutating a constant, either   multiply or divide by (1+perturbationFactor)^(rand()+1).\nprobNegate: Probability of negating a constant in the equation   when mutating it.\nmutationWeights: Relative probabilities of the mutations, in the order: MutateConstant, MutateOperator, AddNode, InsertNode, DeleteNode, Simplify, Randomize, DoNothing.\nannealing: Whether to use simulated annealing.\nwarmupMaxsize: Whether to slowly increase the max size from 5 up to   maxsize. If nonzero, specifies how many cycles (populations*iterations)   before increasing by 1.\nverbosity: Whether to print debugging statements or   not.\nbin_constraints: See constraints. This is the same, but specified for binary   operators only (for example, if you have an operator that is both a binary   and unary operator).\nuna_constraints: Likewise, for unary operators.\nseed: What random seed to use. nothing uses no seed.\nprogress: Whether to use a progress bar output (verbosity will   have no effect).\nprobPickFirst: Expressions in subsample are chosen based on, for   p=probPickFirst: p, p(1-p), p(1-p)^2, and so on.\nearlyStopCondition: Float - whether to stop early if the mean loss gets below this value.   Function - a function taking (loss, complexity) as arguments and returning true or false.\ntimeout_in_seconds: Float64 - the time in seconds after which to exit (as an alternative to the number of iterations).\nmax_evals: Int (or Nothing) - the maximum number of evaluations of expressions to perform.\nskip_mutation_failures: Whether to simply skip over mutations that fail or are rejected, rather than to replace the mutated   expression with the original expression and proceed normally.\nenable_autodiff: Whether to enable automatic differentiation functionality. This is turned off by default.   If turned on, this will be turned off if one of the operators does not have well-defined gradients.\nnested_constraints: Specifies how many times a combination of operators can be nested. For example,   [sin => [cos => 0], cos => [cos => 2]] specifies that cos may never appear within a sin,   but sin can be nested with itself an unlimited number of times. The second term specifies that cos   can be nested up to 2 times within a cos, so that cos(cos(cos(x))) is allowed (as well as any combination   of + or - within it), but cos(cos(cos(cos(x)))) is not allowed. When an operator is not specified,   it is assumed that it can be nested an unlimited number of times. This requires that there is no operator   which is used both in the unary operators and the binary operators (e.g., - could be both subtract, and negation).   For binary operators, both arguments are treated the same way, and the max of each argument is constrained.\ndeterministic: Use a global counter for the birth time, rather than calls to time(). This gives   perfect resolution, and is therefore deterministic. However, it is not thread safe, and must be used   in serial mode.\n\n\n\n\n\n","category":"method"},{"location":"api/#Printing","page":"API","title":"Printing","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"string_tree(tree::Node, options::Options)","category":"page"},{"location":"api/#SymbolicRegression.CoreModule.EquationModule.string_tree-Tuple{Node, Options}","page":"API","title":"SymbolicRegression.CoreModule.EquationModule.string_tree","text":"string_tree(tree::Node, options::Options; kws...)\n\nConvert an equation to a string.\n\nArguments\n\nvarMap::Union{Array{String, 1}, Nothing}=nothing: what variables   to print for each feature.\n\n\n\n\n\n","category":"method"},{"location":"api/#Evaluation","page":"API","title":"Evaluation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"eval_tree_array(tree::Node{T}, cX::AbstractMatrix{T}, options::Options) where {T<:Real}","category":"page"},{"location":"api/#SymbolicRegression.EvaluateEquationModule.eval_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, Options}} where T<:Real","page":"API","title":"SymbolicRegression.EvaluateEquationModule.eval_tree_array","text":"eval_tree_array(tree::Node, cX::AbstractMatrix{T}, options::Options)\n\nEvaluate a binary tree (equation) over a given input data matrix. The options contain all of the operators used. This function fuses doublets and triplets of operations for lower memory usage.\n\nThis function can be represented by the following pseudocode:\n\nfunction eval(current_node)\n    if current_node is leaf\n        return current_node.value\n    elif current_node is degree 1\n        return current_node.operator(eval(current_node.left_child))\n    else\n        return current_node.operator(eval(current_node.left_child), eval(current_node.right_child))\n\nThe bulk of the code is for optimizations and pre-emptive NaN/Inf checks, which speed up evaluation significantly.\n\nReturns\n\n(output, complete)::Tuple{AbstractVector{T}, Bool}: the result,   which is a 1D array, as well as if the evaluation completed   successfully (true/false). A false complete means an infinity   or nan was encountered, and a large loss should be assigned   to the equation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Derivatives","page":"API","title":"Derivatives","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"SymbolicRegression.jl can automatically and efficiently compute derivatives of expressions with respect to variables or constants. This is done using either eval_diff_tree_array, to compute derivative with respect to a single variable, or with eval_grad_tree_array, to compute the gradient with respect all variables (or, all constants). Both use forward-mode automatic, but use Zygote.jl to compute derivatives of each operator, so this is very efficient.","category":"page"},{"location":"api/","page":"API","title":"API","text":"eval_diff_tree_array(tree::Node{T}, cX::AbstractMatrix{T}, options::Options, direction::Int) where {T<:Real}\neval_grad_tree_array(tree::Node{T}, cX::AbstractMatrix{T}, options::Options; variable::Bool=false) where {T<:Real}","category":"page"},{"location":"api/#SymbolicRegression.EvaluateEquationDerivativeModule.eval_diff_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, Options, Int64}} where T<:Real","page":"API","title":"SymbolicRegression.EvaluateEquationDerivativeModule.eval_diff_tree_array","text":"eval_diff_tree_array(tree::Node{T}, cX::AbstractMatrix{T}, options::Options, direction::Int)\n\nCompute the forward derivative of an expression, using a similar structure and optimization to evaltreearray. direction is the index of a particular variable in the expression. e.g., direction=1 would indicate derivative with respect to x1.\n\nArguments\n\ntree::Node: The expression tree to evaluate.\ncX::AbstractMatrix{T}: The data matrix, with each column being a data point.\noptions::Options: The options used to create the tree. Note that options.enable_autodiff   must be true. This is needed to create the derivative operations.\ndirection::Int: The index of the variable to take the derivative with respect to.\n\nReturns\n\n(evaluation, derivative, complete)::Tuple{AbstractVector{T}, AbstractVector{T}, Bool}: the normal evaluation,   the derivative, and whether the evaluation completed as normal (or encountered a nan or inf).\n\n\n\n\n\n","category":"method"},{"location":"api/#SymbolicRegression.EvaluateEquationDerivativeModule.eval_grad_tree_array-Union{Tuple{T}, Tuple{Node{T}, AbstractMatrix{T}, Options}} where T<:Real","page":"API","title":"SymbolicRegression.EvaluateEquationDerivativeModule.eval_grad_tree_array","text":"eval_grad_tree_array(tree::Node{T}, cX::AbstractMatrix{T}, options::Options; variable::Bool=false)\n\nCompute the forward-mode derivative of an expression, using a similar structure and optimization to evaltreearray. variable specifies whether we should take derivatives with respect to features (i.e., cX), or with respect to every constant in the expression.\n\nArguments\n\ntree::Node{T}: The expression tree to evaluate.\ncX::AbstractMatrix{T}: The data matrix, with each column being a data point.\noptions::Options: The options used to create the tree. Note that options.enable_autodiff   must be true. This is needed to create the derivative operations.\nvariable::Bool: Whether to take derivatives with respect to features (i.e., cX - with variable=true),   or with respect to every constant in the expression (variable=false).\n\nReturns\n\n(evaluation, gradient, complete)::Tuple{AbstractVector{T}, AbstractMatrix{T}, Bool}: the normal evaluation,   the gradient, and whether the evaluation completed as normal (or encountered a nan or inf).\n\n\n\n\n\n","category":"method"},{"location":"api/#SymbolicUtils.jl-interface","page":"API","title":"SymbolicUtils.jl interface","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"node_to_symbolic(tree::Node, options::Options; \n                     varMap::Union{Array{String, 1}, Nothing}=nothing,\n                     index_functions::Bool=false)","category":"page"},{"location":"api/#SymbolicRegression.InterfaceSymbolicUtilsModule.node_to_symbolic-Tuple{Node, Options}","page":"API","title":"SymbolicRegression.InterfaceSymbolicUtilsModule.node_to_symbolic","text":"node_to_symbolic(tree::Node, options::Options;\n            varMap::Union{Array{String, 1}, Nothing}=nothing,\n            index_functions::Bool=false)\n\nThe interface to SymbolicUtils.jl. Passing a tree to this function will generate a symbolic equation in SymbolicUtils.jl format.\n\nArguments\n\ntree::Node: The equation to convert.\noptions::Options: Options, which contains the operators used in the equation.\nvarMap::Union{Array{String, 1}, Nothing}=nothing: What variable names to use for   each feature. Default is [x1, x2, x3, ...].\nindex_functions::Bool=false: Whether to generate special names for the   operators, which then allows one to convert back to a Node format   using symbolic_to_node.   (CURRENTLY UNAVAILABLE - See https://github.com/MilesCranmer/SymbolicRegression.jl/pull/84).\n\n\n\n\n\n","category":"method"},{"location":"api/#Pareto-frontier","page":"API","title":"Pareto frontier","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"calculate_pareto_frontier(X::AbstractMatrix{T}, y::AbstractVector{T},\n                        hallOfFame::HallOfFame{T}, options::Options;\n                        weights=nothing, varMap=nothing) where {T<:Real}\ncalculate_pareto_frontier(dataset::Dataset{T}, hallOfFame::HallOfFame{T},\n                          options::Options) where {T<:Real}","category":"page"},{"location":"api/#SymbolicRegression.HallOfFameModule.calculate_pareto_frontier-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{T}, HallOfFame{T}, Options}} where T<:Real","page":"API","title":"SymbolicRegression.HallOfFameModule.calculate_pareto_frontier","text":"calculate_pareto_frontier(X::AbstractMatrix{T}, y::AbstractVector{T},\n                        hallOfFame::HallOfFame{T}, options::Options;\n                        weights=nothing, varMap=nothing) where {T<:Real}\n\nCompute the dominating Pareto frontier for a given hallOfFame. This is the list of equations where each equation has a better loss than all simpler equations.\n\n\n\n\n\n","category":"method"},{"location":"api/#SymbolicRegression.HallOfFameModule.calculate_pareto_frontier-Union{Tuple{T}, Tuple{Dataset{T}, HallOfFame{T}, Options}} where T<:Real","page":"API","title":"SymbolicRegression.HallOfFameModule.calculate_pareto_frontier","text":"calculate_pareto_frontier(dataset::Dataset{T}, hallOfFame::HallOfFame{T},\n                        options::Options) where {T<:Real}\n\n\n\n\n\n","category":"method"},{"location":"losses/#Losses","page":"Losses","title":"Losses","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"These losses, and their documentation, are included from the LossFunctions.jl package.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"Pass the function as, e.g., loss=L1DistLoss().","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"You can also declare your own loss as a function that takes two (unweighted) or three (weighted) scalar arguments. For example,","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"f(x, y, w) = abs(x-y)*w\noptions = Options(loss=f)","category":"page"},{"location":"losses/#Regression:","page":"Losses","title":"Regression:","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"Regression losses work on the distance between targets and predictions: r = x - y.","category":"page"},{"location":"losses/#LPDistLoss{P}-:-DistanceLoss","page":"Losses","title":"LPDistLoss{P} <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The P-th power absolute distance loss. It is Lipschitz continuous iff P == 1, convex if and only if P >= 1, and strictly convex iff P > 1.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = r^P","category":"page"},{"location":"losses/#L1DistLoss-:-DistanceLoss","page":"Losses","title":"L1DistLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The absolute distance loss. Special case of the LPDistLoss with P=1. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = r","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    3 │\\.                     ./│    1 │            ┌------------│\n      │ '\\.                 ./' │      │            |            │\n      │   \\.               ./   │      │            |            │\n      │    '\\.           ./'    │      │_           |           _│\n    L │      \\.         ./      │   L' │            |            │\n      │       '\\.     ./'       │      │            |            │\n      │         \\.   ./         │      │            |            │\n    0 │          '\\./'          │   -1 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -3                        3\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#L2DistLoss-:-DistanceLoss","page":"Losses","title":"L2DistLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The least squares loss. Special case of the LPDistLoss with P=2. It is strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = r^2","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    9 │\\                       /│    3 │                   .r/   │\n      │\".                     .\"│      │                 .r'     │\n      │ \".                   .\" │      │              _./'       │\n      │  \".                 .\"  │      │_           .r/         _│\n    L │   \".               .\"   │   L' │         _:/'            │\n      │    '\\.           ./'    │      │       .r'               │\n      │      \\.         ./      │      │     .r'                 │\n    0 │        \"-.___.-\"        │   -3 │  _/r'                   │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#PeriodicLoss-:-DistanceLoss","page":"Losses","title":"PeriodicLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"Measures distance on a circle of specified circumference c.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = 1 - cos left( frac2 r pic right)","category":"page"},{"location":"losses/#HuberLoss-:-DistanceLoss","page":"Losses","title":"HuberLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"Loss function commonly used for robustness to outliers. For large values of d it becomes close to the L1DistLoss, while for small values of d it resembles the L2DistLoss. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = begincases fracr^22  quad textif   r  le alpha  alpha  r  - fracalpha^32  quad textotherwise endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (d=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │                         │    1 │                .+-------│\n      │                         │      │              ./'        │\n      │\\.                     ./│      │             ./          │\n      │ '.                   .' │      │_           ./          _│\n    L │   \\.               ./   │   L' │           /'            │\n      │     \\.           ./     │      │          /'             │\n      │      '.         .'      │      │        ./'              │\n    0 │        '-.___.-'        │   -1 │-------+'                │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#L1EpsilonInsLoss-:-DistanceLoss","page":"Losses","title":"L1EpsilonInsLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The ϵ-insensitive loss. Typically used in linear support vector regression. It ignores deviances smaller than ϵ, but penalizes larger deviances linearly. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = max  0  r  - epsilon ","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (ϵ=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\                       /│    1 │                  ┌------│\n      │ \\                     / │      │                  |      │\n      │  \\                   /  │      │                  |      │\n      │   \\                 /   │      │_      ___________!     _│\n    L │    \\               /    │   L' │      |                  │\n      │     \\             /     │      │      |                  │\n      │      \\           /      │      │      |                  │\n    0 │       \\_________/       │   -1 │------┘                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#L2EpsilonInsLoss-:-DistanceLoss","page":"Losses","title":"L2EpsilonInsLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The quadratic ϵ-insensitive loss. Typically used in linear support vector regression. It ignores deviances smaller than ϵ, but penalizes larger deviances quadratically. It is convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = max  0  r  - epsilon ^2","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (ϵ=0.5)             Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    8 │                         │    1 │                  /      │\n      │:                       :│      │                 /       │\n      │'.                     .'│      │                /        │\n      │ \\.                   ./ │      │_         _____/        _│\n    L │  \\.                 ./  │   L' │         /               │\n      │   \\.               ./   │      │        /                │\n      │    '\\.           ./'    │      │       /                 │\n    0 │      '-._______.-'      │   -1 │      /                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#LogitDistLoss-:-DistanceLoss","page":"Losses","title":"LogitDistLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The distance-based logistic loss for regression. It is strictly convex and Lipschitz continuous.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = - ln frac4 e^r(1 + e^r)^2","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │                         │    1 │                   _--'''│\n      │\\                       /│      │                ./'      │\n      │ \\.                   ./ │      │              ./         │\n      │  '.                 .'  │      │_           ./          _│\n    L │   '.               .'   │   L' │           ./            │\n      │     \\.           ./     │      │         ./              │\n      │      '.         .'      │      │       ./                │\n    0 │        '-.___.-'        │   -1 │___.-''                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -4                        4\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#QuantileLoss-:-DistanceLoss","page":"Losses","title":"QuantileLoss <: DistanceLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The distance-based quantile loss, also known as pinball loss, can be used to estimate conditional τ-quantiles. It is Lipschitz continuous and convex, but not strictly convex. Furthermore it is symmetric if and only if τ = 1/2.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(r) = begincases -left( 1 - tau  right) r  quad textif  r  0  tau r  quad textif  r ge 0  endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (τ=0.7)             Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │'\\                       │  0.3 │            ┌------------│\n      │  \\.                     │      │            |            │\n      │   '\\                    │      │_           |           _│\n      │     \\.                  │      │            |            │\n    L │      '\\              ._-│   L' │            |            │\n      │        \\.         ..-'  │      │            |            │\n      │         '.     _r/'     │      │            |            │\n    0 │           '_./'         │ -0.7 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -3                        3\n                 ŷ - y                            ŷ - y","category":"page"},{"location":"losses/#Classification:","page":"Losses","title":"Classification:","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"Classifications losses (assuming binary) work on the margin between targets and predictions: r = x y, assuming the target y is either -1 or +1.","category":"page"},{"location":"losses/#ZeroOneLoss-:-MarginLoss","page":"Losses","title":"ZeroOneLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The classical classification loss. It penalizes every misclassified observation with a loss of 1 while every correctly classified observation has a loss of 0. It is not convex nor continuous and thus seldom used directly. Instead one usually works with some classification-calibrated surrogate loss, such as L1HingeLoss.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = begincases 1  quad textif  a  0  0  quad textif  a = 0 endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    1 │------------┐            │    1 │                         │\n      │            |            │      │                         │\n      │            |            │      │                         │\n      │            |            │      │_________________________│\n      │            |            │      │                         │\n      │            |            │      │                         │\n      │            |            │      │                         │\n    0 │            └------------│   -1 │                         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                y * h(x)                         y * h(x)","category":"page"},{"location":"losses/#PerceptronLoss-:-MarginLoss","page":"Losses","title":"PerceptronLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The perceptron loss linearly penalizes every prediction where the resulting agreement <= 0. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = max  0 -a ","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\.                       │    0 │            ┌------------│\n      │ '..                     │      │            |            │\n      │   \\.                    │      │            |            │\n      │     '.                  │      │            |            │\n    L │      '.                 │   L' │            |            │\n      │        \\.               │      │            |            │\n      │         '.              │      │            |            │\n    0 │           \\.____________│   -1 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#LogitMarginLoss-:-MarginLoss","page":"Losses","title":"LogitMarginLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The margin version of the logistic loss. It is infinitely many times differentiable, strictly convex, and Lipschitz continuous.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = ln (1 + e^-a)","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │ \\.                      │    0 │                  ._--/\"\"│\n      │   \\.                    │      │               ../'      │\n      │     \\.                  │      │              ./         │\n      │       \\..               │      │            ./'          │\n    L │         '-_             │   L' │          .,'            │\n      │            '-_          │      │         ./              │\n      │               '\\-._     │      │      .,/'               │\n    0 │                    '\"\"*-│   -1 │__.--''                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -4                        4\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#L1HingeLoss-:-MarginLoss","page":"Losses","title":"L1HingeLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The hinge loss linearly penalizes every prediction where the resulting agreement < 1 . It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = max  0 1 - a ","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    3 │'\\.                      │    0 │                  ┌------│\n      │  ''_                    │      │                  |      │\n      │     \\.                  │      │                  |      │\n      │       '.                │      │                  |      │\n    L │         ''_             │   L' │                  |      │\n      │            \\.           │      │                  |      │\n      │              '.         │      │                  |      │\n    0 │                ''_______│   -1 │------------------┘      │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#L2HingeLoss-:-MarginLoss","page":"Losses","title":"L2HingeLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The truncated least squares loss quadratically penalizes every prediction where the resulting agreement < 1. It is locally Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = max  0 1 - a ^2","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │     .                   │    0 │                 ,r------│\n      │     '.                  │      │               ,/        │\n      │      '\\                 │      │             ,/          │\n      │        \\                │      │           ,/            │\n    L │         '.              │   L' │         ./              │\n      │          '.             │      │       ./                │\n      │            \\.           │      │     ./                  │\n    0 │              '-.________│   -5 │   ./                    │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#SmoothedL1HingeLoss-:-MarginLoss","page":"Losses","title":"SmoothedL1HingeLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"As the name suggests a smoothed version of the L1 hinge loss. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = begincases frac05gamma cdot max  0 1 - a  ^2  quad textif  a ge 1 - gamma  1 - fracgamma2 - a  quad textotherwise endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (γ=2)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\.                       │    0 │                 ,r------│\n      │ '.                      │      │               ./'       │\n      │   \\.                    │      │              ,/         │\n      │     '.                  │      │            ./'          │\n    L │      '.                 │   L' │           ,'            │\n      │        \\.               │      │         ,/              │\n      │          ',             │      │       ./'               │\n    0 │            '*-._________│   -1 │______./                 │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#ModifiedHuberLoss-:-MarginLoss","page":"Losses","title":"ModifiedHuberLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"A special (4 times scaled) case of the SmoothedL1HingeLoss with γ=2. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = begincases max  0 1 - a  ^2  quad textif  a ge -1  - 4 a  quad textotherwise endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │    '.                   │    0 │                .+-------│\n      │     '.                  │      │              ./'        │\n      │      '\\                 │      │             ,/          │\n      │        \\                │      │           ,/            │\n    L │         '.              │   L' │         ./              │\n      │          '.             │      │       ./'               │\n      │            \\.           │      │______/'                 │\n    0 │              '-.________│   -5 │                         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#L2MarginLoss-:-MarginLoss","page":"Losses","title":"L2MarginLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The margin-based least-squares loss for classification, which penalizes every prediction where agreement != 1 quadratically. It is locally Lipschitz continuous and strongly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = left( 1 - a right)^2","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │     .                   │    2 │                       ,r│\n      │     '.                  │      │                     ,/  │\n      │      '\\                 │      │                   ,/    │\n      │        \\                │      ├                 ,/      ┤\n    L │         '.              │   L' │               ./        │\n      │          '.             │      │             ./          │\n      │            \\.          .│      │           ./            │\n    0 │              '-.____.-' │   -3 │         ./              │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#ExpLoss-:-MarginLoss","page":"Losses","title":"ExpLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The margin-based exponential loss for classification, which penalizes every prediction exponentially. It is infinitely many times differentiable, locally Lipschitz continuous and strictly convex, but not clipable.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = e^-a","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │  \\.                     │    0 │               _,,---:'\"\"│\n      │   l                     │      │           _r/\"'         │\n      │    l.                   │      │        .r/'             │\n      │     \":                  │      │      .r'                │\n    L │       \\.                │   L' │     ./                  │\n      │        \"\\..             │      │    .'                   │\n      │           '\":,_         │      │   ,'                    │\n    0 │                \"\"---:.__│   -5 │  ./                     │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#SigmoidLoss-:-MarginLoss","page":"Losses","title":"SigmoidLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"Continuous loss which penalizes every prediction with a loss within in the range (0,2). It is infinitely many times differentiable, Lipschitz continuous but nonconvex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = 1 - tanh(a)","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\"\"'--,.                  │    0 │..                     ..│\n      │      '\\.                │      │ \"\\.                 ./\" │\n      │         '.              │      │    ',             ,'    │\n      │           \\.            │      │      \\           /      │\n    L │            \"\\.          │   L' │       \\         /       │\n      │              \\.         │      │        \\.     ./        │\n      │                \\,       │      │         \\.   ./         │\n    0 │                  '\"-:.__│   -1 │          ',_,'          │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"losses/#DWDMarginLoss-:-MarginLoss","page":"Losses","title":"DWDMarginLoss <: MarginLoss","text":"","category":"section"},{"location":"losses/","page":"Losses","title":"Losses","text":"The distance weighted discrimination margin loss. It is a differentiable generalization of the L1HingeLoss that is different than the SmoothedL1HingeLoss. It is Lipschitz continuous and convex, but not strictly convex.","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"L(a) = begincases 1 - a  quad textif  a ge fracqq+1  frac1a^q fracq^q(q+1)^q+1  quad textotherwise endcases","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"","category":"page"},{"location":"losses/","page":"Losses","title":"Losses","text":"              Lossfunction (q=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │      \".                 │    0 │                     ._r-│\n      │        \\.               │      │                   ./    │\n      │         ',              │      │                 ./      │\n      │           \\.            │      │                 /       │\n    L │            \"\\.          │   L' │                .        │\n      │              \\.         │      │                /        │\n      │               \":__      │      │               ;         │\n    0 │                   '\"\"---│   -1 │---------------┘         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ","category":"page"},{"location":"#SymbolicRegression.jl","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"","category":"section"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Latest release Documentation Build status Coverage\n(Image: version) (Image: Dev) (Image: Stable) (Image: CI) (Image: Coverage Status)","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Distributed High-Performance symbolic regression in Julia.","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Check out PySR for a Python frontend.","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"<img src=\"https://astroautomata.com/data/srdemoimage1.png\" alt=\"demo1\" width=\"700\"/> <img src=\"https://astroautomata.com/data/srdemoimage2.png\" alt=\"demo2\" width=\"700\"/>","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Cite this software","category":"page"},{"location":"#Quickstart","page":"SymbolicRegression.jl","title":"Quickstart","text":"","category":"section"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Install in Julia with:","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"using Pkg\nPkg.add(\"SymbolicRegression\")","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"The heart of this package is the EquationSearch function, which takes a 2D array (shape [features, rows]) and attempts to model a 1D array (shape [rows]) using analytic functional forms.","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Run distributed on four processes with:","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"using SymbolicRegression\n\nX = randn(Float32, 5, 100)\ny = 2 * cos.(X[4, :]) + X[1, :] .^ 2 .- 2\n\noptions = SymbolicRegression.Options(\n    binary_operators=(+, *, /, -),\n    unary_operators=(cos, exp),\n    npopulations=20\n)\n\nhall_of_fame = EquationSearch(X, y, niterations=40, options=options, numprocs=4)","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"We can view the equations in the dominating Pareto frontier with:","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"dominating = calculate_pareto_frontier(X, y, hall_of_fame, options)","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"We can convert the best equation to SymbolicUtils.jl with the following function:","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"eqn = node_to_symbolic(dominating[end].tree, options)\nprintln(simplify(eqn*5 + 3))","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"We can also print out the full pareto frontier like so:","category":"page"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"println(\"Complexity\\tMSE\\tEquation\")\n\nfor member in dominating\n    complexity = compute_complexity(member.tree, options)\n    loss = member.loss\n    string = string_tree(member.tree, options)\n\n    println(\"$(complexity)\\t$(loss)\\t$(string)\")\nend","category":"page"},{"location":"#Contents","page":"SymbolicRegression.jl","title":"Contents","text":"","category":"section"},{"location":"","page":"SymbolicRegression.jl","title":"SymbolicRegression.jl","text":"Pages = [\"api.md\", \"types.md\", \"losses.md\"]","category":"page"},{"location":"types/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"types/#Equations","page":"Types","title":"Equations","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Equations are specified as binary trees with the Node type. Operators defined in Base are re-defined for Node types, so that one can use, e.g., t=Node(\"x1\") * 3f0 to create a tree, so long as * was specified as a binary operator.","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"Node{T<:Real}\nNode(; val::Real=nothing, feature::Integer=nothing)\nNode(op::Int, l::Node)\nNode(op::Int, l::Node, r::Node)\nNode(var_string::String)\nconvert(::Type{Node{T1}}, tree::Node{T2}) where {T1, T2}","category":"page"},{"location":"types/#SymbolicRegression.CoreModule.EquationModule.Node","page":"Types","title":"SymbolicRegression.CoreModule.EquationModule.Node","text":"Node{T<:Real}\n\nNode defines a symbolic expression stored in a binary tree. A single Node instance is one \"node\" of this tree, and has references to its children. By tracing through the children nodes, you can evaluate or print a given expression.\n\nFields\n\ndegree::Int: Degree of the node. 0 for constants, 1 for   unary operators, 2 for binary operators.\nconstant::Bool: Whether the node is a constant.\nval::T: Value of the node. If degree==0, and constant==true,   this is the value of the constant. It has a type specified by the   overall type of the Node (e.g., Float64).\nfeature::Int (optional): Index of the feature to use in the   case of a feature node. Only used if degree==0 and constant==false.    Only defined if degree == 0 && constant == false.\nop::Int: If degree==1, this is the index of the operator   in options.unaops. If degree==2, this is the index of the   operator in options.binops. In other words, this is an enum   of the operators, and is dependent on the specific Options   object. Only defined if degree >= 1\nl::Node{T}: Left child of the node. Only defined if degree >= 1.   Same type as the parent node.\nr::Node{T}: Right child of the node. Only defined if degree == 2.   Same type as the parent node. This is to be passed as the right   argument to the binary operator.\n\n\n\n\n\n","category":"type"},{"location":"types/#SymbolicRegression.CoreModule.EquationModule.Node-Tuple{}","page":"Types","title":"SymbolicRegression.CoreModule.EquationModule.Node","text":"Node(; val::Real=nothing, feature::Integer=nothing)\n\nCreate a leaf node: either a constant, or a variable.\n\nArguments:\n\nval::Real, if you are specifying a constant, pass   the value of the constant here.\nfeature::Integer, if you are specifying a variable,   pass the index of the variable here.\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.CoreModule.EquationModule.Node-Tuple{Int64, Node}","page":"Types","title":"SymbolicRegression.CoreModule.EquationModule.Node","text":"Node(op::Int, l::Node)\n\nApply unary operator op (enumerating over the order given) to Node l\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.CoreModule.EquationModule.Node-Tuple{Int64, Node, Node}","page":"Types","title":"SymbolicRegression.CoreModule.EquationModule.Node","text":"Node(op::Int, l::Node, r::Node)\n\nApply binary operator op (enumerating over the order given) to Nodes l and r\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.CoreModule.EquationModule.Node-Tuple{String}","page":"Types","title":"SymbolicRegression.CoreModule.EquationModule.Node","text":"Node(var_string::String)\n\nCreate a variable node, using the format \"x1\" to mean feature 1\n\n\n\n\n\n","category":"method"},{"location":"types/#Base.convert-Union{Tuple{T2}, Tuple{T1}, Tuple{Type{Node{T1}}, Node{T2}}} where {T1, T2}","page":"Types","title":"Base.convert","text":"convert(::Type{Node{T1}}, n::Node{T2}) where {T1,T2}\n\nConvert a Node{T2} to a Node{T1}. This will recursively convert all children nodes to Node{T1}, using convert(T1, tree.val) at constant nodes.\n\n\n\n\n\n","category":"method"},{"location":"types/#Population","page":"Types","title":"Population","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Groups of equations are given as a population, which is an array of trees tagged with score, loss, and birthdate–-these values are given in the PopMember.","category":"page"},{"location":"types/","page":"Types","title":"Types","text":"Population(pop::Array{PopMember{T}, 1}) where {T<:Real}\nPopulation(dataset::Dataset{T}, baseline::T;\n           npop::Int, nlength::Int=3,\n           options::Options,\n           nfeatures::Int) where {T<:Real}\nPopulation(X::AbstractMatrix{T}, y::AbstractVector{T}, baseline::T;\n           npop::Int, nlength::Int=3,\n           options::Options,\n           nfeatures::Int) where {T<:Real}","category":"page"},{"location":"types/#SymbolicRegression.PopulationModule.Population-Union{Tuple{Array{PopMember{T}, 1}}, Tuple{T}} where T<:Real","page":"Types","title":"SymbolicRegression.PopulationModule.Population","text":"Population(pop::Array{PopMember{T}, 1})\n\nCreate population from list of PopMembers.\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.PopulationModule.Population-Union{Tuple{T}, Tuple{Dataset{T}, T}} where T<:Real","page":"Types","title":"SymbolicRegression.PopulationModule.Population","text":"Population(dataset::Dataset{T}, baseline::T;\n           npop::Int, nlength::Int=3, options::Options,\n           nfeatures::Int)\n\nCreate random population and score them on the dataset.\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.PopulationModule.Population-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{T}, T}} where T<:Real","page":"Types","title":"SymbolicRegression.PopulationModule.Population","text":"Population(X::AbstractMatrix{T}, y::AbstractVector{T},\n           baseline::T; npop::Int, nlength::Int=3,\n           options::Options, nfeatures::Int)\n\nCreate random population and score them on the dataset.\n\n\n\n\n\n","category":"method"},{"location":"types/#Population-members","page":"Types","title":"Population members","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"PopMember(t::Node{T}, score::T, loss::T) where {T<:Real}\nPopMember(dataset::Dataset{T}, baseline::T, t::Node{T}, options::Options) where {T<:Real}","category":"page"},{"location":"types/#SymbolicRegression.PopMemberModule.PopMember-Union{Tuple{T}, Tuple{Node{T}, T, T}} where T<:Real","page":"Types","title":"SymbolicRegression.PopMemberModule.PopMember","text":"PopMember(t::Node, score::T, loss::T)\n\nCreate a population member with a birth date at the current time.\n\nArguments\n\nt::Node: The tree for the population member.\nscore::T: The score (normalized to a baseline, and offset by a complexity penalty)\nloss::T: The raw loss to assign.\n\n\n\n\n\n","category":"method"},{"location":"types/#SymbolicRegression.PopMemberModule.PopMember-Union{Tuple{T}, Tuple{Dataset{T}, T, Node{T}, Options}} where T<:Real","page":"Types","title":"SymbolicRegression.PopMemberModule.PopMember","text":"PopMember(dataset::Dataset{T}, baseline::T,\n          t::Node, options::Options)\n\nCreate a population member with a birth date at the current time. Automatically compute the score for this tree.\n\nArguments\n\ndataset::Dataset{T}: The dataset to evaluate the tree on.\nbaseline::T: The baseline loss.\nt::Node: The tree for the population member.\noptions::Options: What options to use.\n\n\n\n\n\n","category":"method"},{"location":"types/#Hall-of-Fame","page":"Types","title":"Hall of Fame","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"HallOfFame(options::Options, ::Type{T}) where {T<:Real}","category":"page"},{"location":"types/#SymbolicRegression.HallOfFameModule.HallOfFame-Union{Tuple{T}, Tuple{Options, Type{T}}} where T<:Real","page":"Types","title":"SymbolicRegression.HallOfFameModule.HallOfFame","text":"HallOfFame(options::Options, ::Type{T}) where {T<:Real}\n\nCreate empty HallOfFame. The HallOfFame stores a list of PopMember objects in .members, which is enumerated by size (i.e., .members[1] is the constant solution). .exists is used to determine whether the particular member has been instantiated or not.\n\nArguments:\n\noptions: Options containing specification about deterministic.\nT: Type of Nodes to use in the population. e.g., Float64.\n\n\n\n\n\n","category":"method"},{"location":"types/#Dataset","page":"Types","title":"Dataset","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"Dataset(X::AbstractMatrix{T},\n        y::AbstractVector{T};\n        weights::Union{AbstractVector{T}, Nothing}=nothing,\n        varMap::Union{Array{String, 1}, Nothing}=nothing\n       ) where {T<:Real}","category":"page"},{"location":"types/#SymbolicRegression.CoreModule.DatasetModule.Dataset-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{T}}} where T<:Real","page":"Types","title":"SymbolicRegression.CoreModule.DatasetModule.Dataset","text":"Dataset(X::AbstractMatrix{T}, y::AbstractVector{T};\n        weights::Union{AbstractVector{T}, Nothing}=nothing,\n        varMap::Union{Array{String, 1}, Nothing}=nothing)\n\nConstruct a dataset to pass between internal functions.\n\n\n\n\n\n","category":"method"}]
}
